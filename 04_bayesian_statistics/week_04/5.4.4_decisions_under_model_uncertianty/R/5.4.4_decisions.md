decision making under uncertainty
================

Load the data and preprocess

``` r
library(MASS)
data(UScrime)

#Log transform all continuous variables except `So` which is in column 2. 
# We're overwriting the dataframe in this case.

UScrime[,-2] = log(UScrime[,-2])
```

### Run BAS

I am going to run `BAS` using the sampling without replacement option to enumerate all 2<sup>15</sup> models.

``` r
library(BAS)
crime.ZS =  bas.lm(y ~ ., 
                   data=UScrime,
                   prior="ZS-null",
                   modelprior=uniform()) 
```

**Model Choice**

`BAS` has methods defined to return fitted values, `fitted`, using the observed design matrix and predictions at either the observed data or potentially new values, `predict`, as with `lm`.

``` r
muhat.BMA = fitted(crime.ZS, estimator="BMA")
BMA  = predict(crime.ZS, estimator="BMA")

# predict has additional slots for fitted values under BMA, predictions under each model
names(BMA)
```

    ##  [1] "fit"         "Ybma"        "Ypred"       "postprobs"   "se.fit"     
    ##  [6] "se.pred"     "se.bma.fit"  "se.bma.pred" "df"          "best"       
    ## [11] "bestmodel"   "prediction"  "estimator"

Plotting the two sets of fitted values,

``` r
par(mar=c(9, 9, 3, 3))
plot(muhat.BMA, BMA$fit, 
     pch=16, col=myblue,
     xlab=expression(hat(mu[i])), ylab=expression(hat(Y[i])))
abline(0,1)
```

![](5.4.4_decisions_files/figure-markdown_github/unnamed-chunk-1-1.png) we see that they are in perfect agreement. That is always the case as the posterior mean for the regression mean function at a point *x* is the expected posterior predictive value for *Y* at *x*. This is true not only for estimators such as BMA, but the expected values under model selection.

### Inference with model selection

In addition to using BMA, we can use the posterior means under model selection. This corresponds to a decision rule that combines estimation and selection. `BAS` currently implements the following options

**highest probability model:**

``` r
HPM = predict(crime.ZS, estimator="HPM")

# show the indices of variables in the best model where 0 is the intercept
HPM$bestmodel
```

    ## [1]  0  1  3  4  9 11 13 14 15

A little more interpretable version with names:

``` r
(crime.ZS$namesx[HPM$bestmodel +1])[-1]
```

    ## [1] "M"    "Ed"   "Po1"  "NW"   "U2"   "Ineq" "Prob" "Time"

This model is stored in the output in position 20435 and can be extracted as

``` r
HPM$best
```

    ## [1] 20435

If we wanted to find the coefficients for this model for example, we could use the following:

``` r
crime.coef.ZS = coef(crime.ZS)
crime.coef.ZS$conditionalmeans[HPM$best,]
```

    ##  Intercept          M         So         Ed        Po1        Po2 
    ##  6.7249362  1.4242242  0.0000000  2.1403131  0.8214052  0.0000000 
    ##         LF        M.F        Pop         NW         U1         U2 
    ##  0.0000000  0.0000000  0.0000000  0.1049124  0.0000000  0.2782315 
    ##        GDP       Ineq       Prob       Time 
    ##  0.0000000  1.1926928 -0.2991037 -0.2761578

``` r
crime.coef.ZS$conditionalsd[HPM$best,]
```

    ##  Intercept          M         So         Ed        Po1        Po2 
    ## 0.02622507 0.42277800 0.00000000 0.43094267 0.15927491 0.00000000 
    ##         LF        M.F        Pop         NW         U1         U2 
    ## 0.00000000 0.00000000 0.00000000 0.03821043 0.00000000 0.12492340 
    ##        GDP       Ineq       Prob       Time 
    ## 0.00000000 0.27734344 0.08723967 0.14573850

to extract the posterior means and posterior standard deviations of the coefficients of the highest probability model.

**median probability model:**

``` r
MPM = predict(crime.ZS, estimator="MPM")
attr(MPM$fit, 'model')
```

    ## [1]  0  1  3  4  9 11 13 14

``` r
(crime.ZS$namesx[attr(MPM$fit, 'model') +1])[-1]
```

    ## [1] "M"    "Ed"   "Po1"  "NW"   "U2"   "Ineq" "Prob"

Note that we can also extract the best model from the attribute in the fitted values as well.

For obtaining fitted or predicted values, the media probability model may not be part of the sample (in the general case without enumeration) so the fitted and predict code in BAS actually just refits this model initializing BAS at this model. Here is actually what is under the hood in case you wanted to find coefficients for the MPM.

``` r
crime.MPM = bas.lm(y ~ ., 
                   data=UScrime,
                   prior="ZS-null",
                   modelprior=uniform(),
                   bestmodel=crime.ZS$probne0 > .5, n.models=1) 
```

The logical condition `crime.ZS$probne0` provides a vector of length 16 of the inclusion indicators of the median probabilty model, e.g. where the probabilty that the coefficient is not 0 is greater than 0.5. The option `n.models = 1` fits just this model.

Using the `coef` function applied to just this model we can extract the coefficients for the HPM model:

``` r
coef(crime.MPM)
```

    ## 
    ##  Marginal Posterior Summaries of Coefficients: 
    ##            post mean  post SD   post p(B != 0)
    ## Intercept   6.72494    0.02713   1.00000      
    ## M           1.46180    0.43727   1.00000      
    ## So          0.00000    0.00000   0.00000      
    ## Ed          2.30642    0.43727   1.00000      
    ## Po1         0.87886    0.16204   1.00000      
    ## Po2         0.00000    0.00000   0.00000      
    ## LF          0.00000    0.00000   0.00000      
    ## M.F         0.00000    0.00000   0.00000      
    ## Pop         0.00000    0.00000   0.00000      
    ## NW          0.08162    0.03743   1.00000      
    ## U1          0.00000    0.00000   0.00000      
    ## U2          0.31053    0.12816   1.00000      
    ## GDP         0.00000    0.00000   0.00000      
    ## Ineq        1.18815    0.28710   1.00000      
    ## Prob       -0.18401    0.06466   1.00000      
    ## Time        0.00000    0.00000   0.00000

**best predictive model:**

This is the model that is closest to BMA predictions under squared error loss.

``` r
BPM = predict(crime.ZS, estimator="BPM")
(crime.ZS$namesx[attr(BPM$fit, 'model') +1])[-1]
```

    ##  [1] "M"    "So"   "Ed"   "Po1"  "Po2"  "M.F"  "NW"   "U2"   "Ineq" "Prob"

Let's see how they compare:

``` r
myblue = rgb(86,155,189, name="myblue", max=256)
mydarkgrey = rgb(.5,.5,.5, name="mydarkgrey", max=1)
par(cex=1.8, cex.axis=1.8, cex.lab=2, mfrow=c(2,2), mar=c(5, 5, 3, 3), col.lab=mydarkgrey, col.axis=mydarkgrey, col=mydarkgrey)
library(GGally)
ggpairs(data.frame(HPM = as.vector(HPM$fit),  #this used predict so we need to extract fitted values
                   MPM = as.vector(MPM$fit),  # this used fitted
                   BPM = as.vector(BPM$fit),  # this used fitted
                   BMA = as.vector(BMA$fit))) # this used predict
```

![](5.4.4_decisions_files/figure-markdown_github/unnamed-chunk-6-1.png)

Using the `se.fit = TRUE` option with `predict` we can also calculate standard deviations for prediction or for the mean and use this as imput for the `confint` function for the prediction object.

``` r
BPM = predict(crime.ZS, estimator="BPM", se.fit=TRUE)
crime.conf.fit = confint(BPM, parm="mean")
crime.conf.pred = confint(BPM, parm="pred")
cbind(BPM$fit, crime.conf.fit, crime.conf.pred)
```

    ##                  2.5  %  97.5  %     mean   2.5  %  97.5  %     pred
    ##  [1,] 6.668988 6.513238 6.824738 6.668988 6.258715 7.079261 6.668988
    ##  [2,] 7.290854 7.151787 7.429921 7.290854 6.886619 7.695089 7.290854
    ##  [3,] 6.202166 6.039978 6.364354 6.202166 5.789406 6.614926 6.202166
    ##  [4,] 7.661307 7.490608 7.832006 7.661307 7.245129 8.077484 7.661307
    ##  [5,] 7.015570 6.847647 7.183493 7.015570 6.600523 7.430617 7.015570
    ##  [6,] 6.469547 6.279276 6.659818 6.469547 6.044966 6.894128 6.469547
    ##  [7,] 6.776133 6.555130 6.997135 6.776133 6.336920 7.215346 6.776133
    ##  [8,] 7.299560 7.117166 7.481955 7.299560 6.878450 7.720670 7.299560
    ##  [9,] 6.614927 6.482384 6.747470 6.614927 6.212890 7.016964 6.614927
    ## [10,] 6.596912 6.468988 6.724836 6.596912 6.196374 6.997449 6.596912
    ## [11,] 7.032834 6.877582 7.188087 7.032834 6.622750 7.442918 7.032834
    ## [12,] 6.581822 6.462326 6.701317 6.581822 6.183896 6.979748 6.581822
    ## [13,] 6.467921 6.281998 6.653843 6.467921 6.045271 6.890571 6.467921
    ## [14,] 6.566239 6.403813 6.728664 6.566239 6.153385 6.979092 6.566239
    ## [15,] 6.550129 6.388987 6.711270 6.550129 6.137779 6.962479 6.550129
    ## [16,] 6.888592 6.746097 7.031087 6.888592 6.483166 7.294019 6.888592
    ## [17,] 6.252735 6.063944 6.441526 6.252735 5.828815 6.676654 6.252735
    ## [18,] 6.795764 6.564634 7.026895 6.795764 6.351369 7.240160 6.795764
    ## [19,] 6.945687 6.766289 7.125086 6.945687 6.525866 7.365508 6.945687
    ## [20,] 7.000331 6.840374 7.160289 7.000331 6.588442 7.412220 7.000331
    ## [21,] 6.613748 6.443389 6.784108 6.613748 6.197710 7.029787 6.613748
    ## [22,] 6.509534 6.352123 6.666946 6.509534 6.098628 6.920441 6.509534
    ## [23,] 6.781430 6.589687 6.973172 6.781430 6.356187 7.206672 6.781430
    ## [24,] 6.801865 6.659905 6.943825 6.801865 6.396626 7.207104 6.801865
    ## [25,] 6.368493 6.187973 6.549014 6.368493 5.948191 6.788795 6.368493
    ## [26,] 7.406220 7.173560 7.638879 7.406220 6.961027 7.851412 7.406220
    ## [27,] 5.995056 5.780243 6.209869 5.995056 5.558924 6.431187 5.995056
    ## [28,] 7.130996 6.970370 7.291621 7.130996 6.718847 7.543144 7.130996
    ## [29,] 7.084303 6.904331 7.264275 7.084303 6.664237 7.504370 7.084303
    ## [30,] 6.519208 6.360876 6.677539 6.519208 6.107948 6.930468 6.519208
    ## [31,] 6.191546 5.952977 6.430114 6.191546 5.743237 6.639854 6.191546
    ## [32,] 6.646586 6.472328 6.820844 6.646586 6.228936 7.064236 6.646586
    ## [33,] 6.778853 6.591383 6.966323 6.778853 6.355520 7.202186 6.778853
    ## [34,] 6.813627 6.683297 6.943958 6.813627 6.412314 7.214940 6.813627
    ## [35,] 6.686652 6.503099 6.870205 6.686652 6.265039 7.108265 6.686652
    ## [36,] 7.046639 6.788852 7.304426 7.046639 6.587815 7.505464 7.046639
    ## [37,] 6.786861 6.601977 6.971745 6.786861 6.364667 7.209055 6.786861
    ## [38,] 6.306094 6.128026 6.484162 6.306094 5.886840 6.725348 6.306094
    ## [39,] 6.600676 6.460387 6.740965 6.600676 6.196020 7.005333 6.600676
    ## [40,] 7.094493 6.934796 7.254189 7.094493 6.682705 7.506280 7.094493
    ## [41,] 6.595673 6.374613 6.816734 6.595673 6.156431 7.034916 6.595673
    ## [42,] 6.005732 5.761671 6.249794 6.005732 5.554476 6.456988 6.005732
    ## [43,] 6.962800 6.822918 7.102682 6.962800 6.558285 7.367316 6.962800
    ## [44,] 7.065421 6.910261 7.220580 7.065421 6.655371 7.475470 7.065421
    ## [45,] 6.266709 6.060228 6.473190 6.266709 5.834621 6.698797 6.266709
    ## [46,] 6.511698 6.315350 6.708046 6.511698 6.084359 6.939037 6.511698
    ## [47,] 6.823072 6.644370 7.001773 6.823072 6.403548 7.242596 6.823072

Which state has the highest predicted crime rate? the lowest?

``` r
# lowest 
best = which.min(BPM$fit)
crime.ZS$X[best, BPM$bestmodel]
```

    ## (Intercept)           M          So          Ed         Po1          LF 
    ##    1.000000    4.905275    0.000000    4.691348    4.234107    6.291569 
    ##         Pop          U1         GDP        Ineq 
    ##    1.791759    4.382027    6.335054    4.934474

What characteristics lead to the lowest rates? (where do the X values fall in the distribution of the covariantes - are they at the extremes?)

Using the `newdata` option as with the `predict` function in `lm`, you can predict at new values of the covariates (OK in this case the data frame is the same, so it is the same as the insample prediction). The code below illustrates using BMA and Monte Carlo simulation to obtain the intervals.

``` r
BPM = predict(crime.ZS, UScrime, estimator="BMA", se.fit=TRUE, nsim=10000)
crime.conf.fit = confint(BPM, parm="mean")
crime.conf.pred = confint(BPM, parm="pred")
cbind(BPM$fit, crime.conf.fit, crime.conf.pred)
```

    ##                  2.5  %  97.5  %     mean   2.5  %  97.5  %     pred
    ##  [1,] 6.661770 6.508458 6.806660 6.661770 6.241839 7.084755 6.661770
    ##  [2,] 7.298827 7.124376 7.452355 7.298827 6.890004 7.722050 7.298827
    ##  [3,] 6.179308 5.966081 6.411106 6.179308 5.739905 6.640816 6.179308
    ##  [4,] 7.610585 7.387686 7.837989 7.610585 7.154769 8.047560 7.610585
    ##  [5,] 7.054238 6.856960 7.274190 7.054238 6.622612 7.492986 7.054238
    ##  [6,] 6.514064 6.285696 6.737092 6.514064 6.074487 6.987166 6.514064
    ##  [7,] 6.784846 6.503475 7.073694 6.784846 6.289114 7.259414 6.784846
    ##  [8,] 7.266344 7.036836 7.481564 7.266344 6.822513 7.719638 7.266344
    ##  [9,] 6.629448 6.479831 6.776787 6.629448 6.220613 7.030056 6.629448
    ## [10,] 6.601246 6.456430 6.733261 6.601246 6.200074 7.007591 6.601246
    ## [11,] 7.055003 6.873619 7.245821 7.055003 6.630040 7.489145 7.055003
    ## [12,] 6.570625 6.419409 6.714164 6.570625 6.158183 6.972925 6.570625
    ## [13,] 6.472327 6.203374 6.717909 6.472327 5.987857 6.922116 6.472327
    ## [14,] 6.582374 6.386472 6.759980 6.582374 6.141785 6.995793 6.582374
    ## [15,] 6.556880 6.364360 6.762870 6.556880 6.131589 6.996036 6.556880
    ## [16,] 6.905017 6.749645 7.069837 6.905017 6.482785 7.318458 6.905017
    ## [17,] 6.229073 6.000452 6.479364 6.229073 5.764039 6.677556 6.229073
    ## [18,] 6.809572 6.549314 7.105227 6.809572 6.305155 7.276656 6.809572
    ## [19,] 6.943294 6.763797 7.138297 6.943294 6.510416 7.362593 6.943294
    ## [20,] 6.961980 6.769636 7.135599 6.961980 6.515458 7.377793 6.961980
    ## [21,] 6.608947 6.403165 6.824321 6.608947 6.169944 7.048408 6.608947
    ## [22,] 6.429088 6.170481 6.656666 6.429088 5.981414 6.895749 6.429088
    ## [23,] 6.898828 6.693802 7.122614 6.898828 6.456707 7.336673 6.898828
    ## [24,] 6.777130 6.605017 6.949850 6.777130 6.361684 7.209831 6.777130
    ## [25,] 6.405741 6.213553 6.602424 6.405741 5.951916 6.817669 6.405741
    ## [26,] 7.401082 7.149571 7.662834 7.401082 6.948258 7.878581 7.401082
    ## [27,] 6.019651 5.787607 6.264739 6.019651 5.591494 6.495627 6.019651
    ## [28,] 7.156541 6.946952 7.337362 7.156541 6.730370 7.587825 7.156541
    ## [29,] 7.089698 6.867259 7.308813 7.089698 6.639154 7.519220 7.089698
    ## [30,] 6.500233 6.311500 6.681536 6.500233 6.071765 6.932477 6.500233
    ## [31,] 6.208963 5.998239 6.418925 6.208963 5.748380 6.635587 6.208963
    ## [32,] 6.605944 6.399380 6.790519 6.605944 6.158007 7.030311 6.605944
    ## [33,] 6.798139 6.625123 6.969634 6.798139 6.375546 7.226270 6.798139
    ## [34,] 6.820052 6.696051 6.950010 6.820052 6.415802 7.246252 6.820052
    ## [35,] 6.625465 6.423606 6.823427 6.625465 6.196128 7.066870 6.625465
    ## [36,] 7.029051 6.717454 7.342972 7.029051 6.533953 7.512109 7.029051
    ## [37,] 6.794004 6.546255 7.020840 6.794004 6.314541 7.218555 6.794004
    ## [38,] 6.363691 6.141401 6.592439 6.363691 5.896213 6.806129 6.363691
    ## [39,] 6.603108 6.461905 6.746971 6.603108 6.191713 7.020882 6.603108
    ## [40,] 7.044736 6.883999 7.221374 7.044736 6.624756 7.469258 7.044736
    ## [41,] 6.548160 6.319236 6.792048 6.548160 6.095433 7.004964 6.548160
    ## [42,] 6.046124 5.750680 6.330322 6.046124 5.548799 6.528373 6.046124
    ## [43,] 6.929741 6.744381 7.112831 6.929741 6.470949 7.344683 6.929741
    ## [44,] 7.006019 6.830406 7.178576 7.006019 6.593292 7.446324 7.006019
    ## [45,] 6.236002 5.993820 6.482037 6.236002 5.776006 6.690337 6.236002
    ## [46,] 6.608591 6.367292 6.856480 6.608591 6.169320 7.082514 6.608591
    ## [47,] 6.830450 6.653950 7.018723 6.830450 6.402822 7.256477 6.830450
