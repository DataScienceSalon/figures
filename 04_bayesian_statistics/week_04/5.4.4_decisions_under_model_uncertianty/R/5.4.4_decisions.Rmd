---
title: "decision making under uncertainty"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
myblue = rgb(86,155,189, name="myblue", max=256)
mydarkgrey = rgb(.5,.5,.5, name="mydarkgrey", max=1)
```

Load the data and preprocess
```{r data}
library(MASS)
data(UScrime)

#Log transform all continuous variables except `So` which is in column 2. 
# We're overwriting the dataframe in this case.

UScrime[,-2] = log(UScrime[,-2])
```
### Install BAS ###
We need to install `BAS` from github to have the most recent version as the new predict options are not in version 1.2.2 on CRAN. 

```{r git}
library(devtools)
install_github("merliseclyde/BAS")  # need version > 1.2.2
```

### Run BAS ###

I am going to run `BAS` using the sampling without replacement option to enumerate all $2^15$ models. 
```{r BAS}
library(BAS)
crime.ZS =  bas.lm(y ~ ., 
                   data=UScrime,
                   prior="ZS-null",
                   modelprior=uniform()) 
```


**Model Choice**

`BAS` has methods defined to return fitted values, `fitted`, using the observed design matrix and predictions at either the observed data or potentially new values, `predict`, as with `lm`.


```{r choice of estimator}
muhat.BMA = fitted(crime.ZS, estimator="BMA")
BMA  = predict(crime.ZS, estimator="BMA")

# predict has additional slots for fitted values under BMA, predictions under each model
names(BMA)
```

Plotting the two sets of fitted values,
```{r}
par(mar=c(9, 9, 3, 3))
plot(muhat.BMA, BMA$fit, 
     pch=16, col=myblue,
     xlab=expression(hat(mu[i])), ylab=expression(hat(Y[i])))
abline(0,1)
```
we see that they are in perfect agreement.  That is always the case as the posterior mean for the regression mean function at a point $x$ is the expected posterior  predictive value for $Y$ at $x$.   This is true not only for estimators such as BMA, but the expected values under model selection.   

### Inference with model selection ###

In addition to using BMA, we can use the posterior means under model selection.  This corresponds to a decision rule that combines estimation and selection.  `BAS` currently implements the following options


**highest probability model:**

```{r}
HPM = predict(crime.ZS, estimator="HPM")

# show the indices of variables in the best model where 0 is the intercept
HPM$bestmodel
```

A little more interpretable version with names:
```{r}
(crime.ZS$namesx[HPM$bestmodel +1])[-1]
```

**median probability model:**
```{r}
MPM = fitted(crime.ZS, estimator="MPM")
(crime.ZS$namesx[attr(MPM, 'model') +1])[-1]
```

Note that we can also extract the best model from the attribute in the fitted values as well.

**best predictive model:**

This is the model that is closest to BMA predictions under squared error loss.
```{r}
BPM = fitted(crime.ZS, estimator="BPM")
(crime.ZS$namesx[attr(BPM, 'model') +1])[-1]
```

Let's see how they compare:

```{r}
myblue = rgb(86,155,189, name="myblue", max=256)
mydarkgrey = rgb(.5,.5,.5, name="mydarkgrey", max=1)
par(cex=1.8, cex.axis=1.8, cex.lab=2, mfrow=c(2,2), mar=c(5, 5, 3, 3), col.lab=mydarkgrey, col.axis=mydarkgrey, col=mydarkgrey)
library(GGally)
ggpairs(data.frame(HPM = as.vector(HPM$fit),  #this used predict so we need to extract fitted values
                   MPM = as.vector(MPM),  # this used fitted
                   BPM = as.vector(BPM),  # this used fitted
                   BMA = as.vector(BMA$fit))) # this used predict
```

