5.3.3 Bayesian model averaging
================
Dr. Merlise Clyde, Duke University

**Read In Data and Preprocess**

The data are available as a "dta" file from Gelman's website. You will need to load the `foreign` library to be able to read the file in as a dataframe.

``` r
library(foreign)
cognitive = read.dta("http://www.stat.columbia.edu/~gelman/arm/examples/child.iq/kidiq.dta")
cognitive$mom_work = as.numeric(cognitive$mom_work > 1)
cognitive$mom_hs =  as.numeric(cognitive$mom_hs > 0)
colnames(cognitive) = c("kid_score", "hs","iq", "work", "age") 
```

*Note: you do not need to use the as.numeric function to convert them to 0 or 1 values and could leave them as TRUE/FALSE, however, since the "levels"" appear in the labels in the plot I converted them so that the labels were shorter. Similarly, the variable names were shortened also for cosmetic reasons for the slides only.*

**Bayesian Model Averaging using BAS**

You will need to install the `BAS` package from `CRAN` and load the library.

``` r
library(BAS)
cog_bas = bas.lm(kid_score ~ hs + iq + work + age,
                prior="BIC",
                modelprior=uniform(),
                data=cognitive)
```

To visualize the space of models, use the `image` function.

``` r
image(cog_bas, rotate=F)
```

![](5-3-3-BMA_files/figure-markdown_github/unnamed-chunk-1-1.png)

**Coefficient Summaries**

To calculate the posterior distributions of the coefficients, we use the `coef` function create an object with posterior means and standard deviations using BMA.

``` r
cog_coef = coef(cog_bas)
```

To plot the posterior distributions of the four regression coefficents, use the `plot` function.

``` r
par(mfrow=c(2,2))
plot(cog_coef, subset=c(2:5), ask=F)
```

![](5-3-3-BMA_files/figure-markdown_github/unnamed-chunk-2-1.png)

The optional subset argument lets you select which coefficients to plot from the indices `1:(p+1)`. In this case the intercept `subset=1` has been omitted to create the two by two array of plots.

To obtain the numerical summaries of means, standard deviations and posterior inclusion probabilites, simply type the name of the coefficient object.

``` r
cog_coef
```

    ## 
    ##  Marginal Posterior Summaries of Coefficients: 
    ##            post mean  post SD   post p(B != 0)
    ## Intercept  86.79724    0.87287   1.00000      
    ## hs          3.59494    3.35643   0.61064      
    ## iq          0.58101    0.06363   1.00000      
    ## work        0.36696    1.30939   0.11210      
    ## age         0.02089    0.11738   0.06898

We can also extract credible intervals using the `confint` function.

``` r
confint(cog_coef, nsim=10000)
```

    ##                 2.5  %    97.5  %
    ## Intercept 85.093056416 88.5825125
    ## hs         0.000000000  8.9796381
    ## iq         0.457699212  0.7117680
    ## work       0.000000000  4.0009620
    ## age       -0.002782551  0.2566319
    ## attr(,"Probability")
    ## [1] 0.95

*Note: `BAS` currently centers all covariates. This does not change the slope coefficients, however the intercept in all models is \(\bar{Y}\). *

### Posterior inclusion probabilites

Finally calculate the probabiliy that the coefficient for age is zero. The marginal posterior inclusion probabilities are stored in the `bas` object as `probne0`.

``` r
# probability coefficients are zero
cog_bas$probne0
```

    ## [1] 1.00000000 0.61063772 1.00000000 0.11210135 0.06897758

``` r
cog_coef$probne0
```

    ## [1] 1.00000000 0.61063772 1.00000000 0.11210135 0.06897758

``` r
p = 4
p.age = round(1 - cog_coef$probne0[p+1], 3)

p.age  # probability coefficient for age is zero
```

    ## [1] 0.931

*The intercept is always in position 1, so we need to add one to p to extract the last coefficient corresponding to the variable age.*
